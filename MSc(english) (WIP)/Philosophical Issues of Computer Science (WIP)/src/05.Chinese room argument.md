
# Minds and brains: the Chinese room argument

Could a machine think? 
The Chinese Room Argument is a key experiment in understanding the difference between real understanding and simulated understanding. 
We can define two hyphotesis:

- Weak AI: When a computer is used as a tool to aid in the study of the mind.
- Strong AI: When a computer is programmed with cognitive abilities and can be considered a mind in itself.


Strong AI is a very strong position and **[the physical system hypothesis](04.The%20physical%20system%20hypothesis.md), introduced by Newell and Simon, supports this idea.**

Searle's critical target. There exists a difference between real understanding and mere simulation of understanding (storm and simulation of the storm). 

The chinese room argument is a Gedankenexperiment experiment, which it means it's the German term, but it's a **thought** experiment. Thought experiments are very much using philosophy in science as well, they are like the sort of exercise of imagination.

> "Don't write in your paper that Chinese argument is a real experiment, so that you want to discuss saying it's not possible and stuff like this. That's not the core. It's an argumentation."

The Chinese Room argument is exactly the opposite of the Physical System hypothesis. Partially the Chinese Room is based on the concept of **what intentionality is**.
Intentionality is not who have intentions, it is something more sophisticated from a philosophical point of view.

### The Chinese Room System 

Consider a system with multiple elements including a person who only speaks English and is locked in a room. The room contains:

- a rule ledger written in English
- sheets of paper, some of which are blank while others have meaningless symbols for the person. 

The room is locked, allowing for communication with the outside world despite being locked. The person behaves like a computer: he performs operations on formally specified elements but for him they are meaningless. From the outside the answers appear indistinguishable.
The key point is that basically you don't have any real understanding.
So, according to the paper, a CPU could pass the Turing test and executing the English rules but it remains incapable of comprehending its inputs and outputs. 
This intuition is quite powerful.

### The structure of Searle’s argument

The paper assumes the following four axioms: 

1. Computer programs are formal (syntactic) entities. 
2. Human minds have a mental (semantic) content. 
3. Syntax alone does not constitute semantics; neither is sufficient for it. 
4. Brains cause minds.

Using the Chinese Room Argumenti the limitations of the [Turing Test](03.Turing%20Test.md) are evident as it fails to prove the thinking capabilities of machines. Simply passing the Turing test does not necessarily indicate a machine's true understanding of the inputs and outputs it processes.
It's quite clear that from axioms 1,2,3 we can conclude that programs are not sufficient to cause minds.
At the same time the axioms are a little bit controversial: 

- Axioms 1 and 2 distinguish between syntax and semantics without further explanation.
- It is unclear if axiom 3 is acceptable.

### Some of the famous objections 

Searle's paper divides the responses into three categories:

1. Those admitting that the person in the room does not understand Chinese, but claiming that there is something that does understand Chinese
2. Those saying that Searle describes a system which doesn't understand Chinese, but a modified version of it could. For example a system that can act in the space, walking, moving etc. The Searle's reply is that robot’s sensors and actuators are just other syntactic inputs and outputs.
3. Those who sustain that the person in the room understand Chinese.
4. Those who supports "the other minds reply" which is based on "how can we sure that other people understand chinese?". 

The last part of the paper is like a Q&A: 

- A machine can think and we are an example of such machines.
- It is only possible for an artifact, a man-made machine, to think if it has a nervous system and neurons like ours. (So the biological aspect is very important). 
- Just being a computer with the right program is not enough for something to think and understand.
- Formal symbol manipulations alone can't have intentionality.

The biological aspect:

- Symbol manipulation lacks intentionality.
- Only a system with the same causal power as the brain can have intentionality.
- Causal properties of the brain are essential for causing intentionality.