# Object detection

The challenge combines both challenges of object detection and semantic segmentation: do semantic segmentation and at same time separate each object instance. 


![](images/2ec3490a989e3d5fb5eb898b2abce045.png)

Object detection encompasses identifying and localinzig multiple objects within an image. It involves not only classifying objects but also determining their positions.

- **Early Methods**:
	- **The sliding window** technique involves moving a fixed-size window across an image, at every position using a classifier to determine whether an object of interest is present within that window.
	    - The window "slides" across the image, both horizontally and vertically, often at varying scales (sizes) to detect objects at different resolutions.
	    - At each position, the region within the window is fed into a classifier (like a CNN) to assess whether it contains the object of interest.
	    - This process generates a set of bounding boxes where the classifier predicts the presence of an object.
	    - **Computational Intensity**: Scanning the entire image at multiple scales and positions is computationally expensive.
	    - **Bad accuracy**: The technique may miss objects that don't fit well into the window or generate false positives.
	- **Region proposal** algorithms aim to identify bounding boxes that could potentially contain an object within the image. Before deep learning, algorithms with high recall but low precision tactics were used. The process involves utilizing a region proposal algorithm to determine potential object areas and then using a Convolutional Neural Network (CNN) to classify the image within each proposed region.
- **Modern Approaches**: Use DL, particularly CNNs, which have significantly improved accuracy and efficiency. These include two-stage detectors like R-CNN (and its variants Fast R-CNN, Faster R-CNN) and one-stage detectors like YOLO (You Only Look Once) and SSD (Single Shot Multibox Detector).
	- **Improvements over simple approaches**:
	    - **Efficiency**: Modern object detectors process an entire image in one go, eliminating the need for exhaustive sliding window scanning.
	    - **Accuracy**: They are more accurate in detecting objects of various sizes and shapes, thanks to advanced network architectures and training techniques.
	    - **Speed**: Techniques like YOLO and SSD are optimized for real-time detection, making them suitable for applications like video surveillance and autonomous driving.

### R-CNN (Region-based Convolutional Neural Network)

**R-CNN** (Region-based Convolutional Neural Network) combines region proposals with CNN-based classification and bounding box refinement.
Its main limitations is that it isn't end-to-end trainable and requires separate stages for proposing and classifying. Training involves numerous steps, including fine-tuning with a softmax classifier and training a linear SVM, which can be time consuming due to its inability to reuse features across Region of Interest. Furthermore, it demands substantial storage.
### Fast R-CNN

Fast R-CNN, an advancement over R-CNN, introduces the use of **Region of Interest** (ROI) pooling. This operation enables the network to handle regions of varying sizes and shapes by extracting fixed-size feature vectors. 
Fast R-CNN primarily utilizes the ROI pooling following a region proposal step in the object detection networks, aiding in proposing various regions or candidate object bounding boxes for classification. This component allows for precise object detection and localization by bridging the gap between region proposal and object classification.
The efficiency of Fast R-CNN facilitates end-to-end training with a single CNN execution. 

### Faster R-CNN

Rather than using the ROI extraction algorithm, we train a **Region Proposal Network** (RPN), a Fully Convolutional Neural Network that employs a 3x3 filter size: 
- The RPN operates at the final convolution layers, using the same feature maps for classification. 
- It enhances the efficiency of Fast R-CNN by pinpointing regions with the highest object detection potential using fixed-size bounding boxes, or anchors. These anchors align with potential objects and allow for end-to-end training of the detection model.

The training process involves sequential training of both the RPN and Fast R-CNN components, incorporating four losses: RPN classification and regression, final classification score, and final bounding box coordinates. This integrated approach of region proposal and feature extraction in a single pass makes the network more efficient than its counterparts.

### YOLO

YOLO, or "You Only Look Once," is a state-of-the-art, **real-time** object detection system that simplifies object detection into a single regression problem, solved by a large Convolutional Neural Network (CNN). This departure from traditional methods like R-CNN that use a two-stage approach offers unique strengths and limitations.
The methods based on the two-step approach are challenging to optimize. YOLO turns the entire object detection into a single regression problem. This problem goes from image pixels to boundary box coordinates and class probability. This regression problem is solved by using a large Convolutional Neural Network (CNN).

YOLO divides the input image into a grid. Each grid cell is responsible for detecting objects that fall into it. Each cell predicts a certain number of bounding boxes. For each bounding box, the model predicts the coordinates, the confidence score (how confident it is that a box contains an object), and the probability distribution over all the potential classes.
**Combined Prediction**: The detection is the combination of the confidence score and the class probability.

### Siamese Networks

Siamese Networks are unique neural network models designed to compare the similarities of inputs, making them ideal for tasks like image matching and face verification. Instead of categorizing inputs, these networks evaluate how similar or dissimilar they are, suiting them for comparison-based applications such as face recognition and signature verification.
Key aspects of Siamese Networks include:

- **Feature Extraction Over Classification**: Unlike typical classification networks, Siamese Networks focus on extracting latent features that provide a meaningful representation of images. These features capture patterns crucial for the comparison tasks rather than direct classification.
- **Distance-Based Comparison**: Image features are extracted for comparison through a network that calculates the distance between latent representations. The closest match is determined by the smallest distance in this **latent space**. 
	- **Optimization**: The network is trained to effectively recognize different classes by optimizing weights. This is aimed at making sure images from the same class are closer in latent space as compared to those from different classes.. 
- **Loss Functions**:
    - **Contrastive Loss**: This loss function is used to train the network on pairs of images, focusing on minimizing distances between similar images and maximizing distances between dissimilar ones.
    - **Triplet Loss**: Another approach to training, where the network learns from triplets of images:
	    - an anchor
	    - a positive example (same class)
	    - a negative example (different class)
		The goal is to ensure that the distance between the anchor and the positive example is smaller than the distance between the anchor and the negative example, by a margin `m`.
- **Decision-making strategies**: Different  can be adopted, such as searching for the template that is closest to the input image. The process of image verification involves to associate the input with the class which minimizes the average distance between the input to the templates. The reliability of identification depends on a certain threshold.




