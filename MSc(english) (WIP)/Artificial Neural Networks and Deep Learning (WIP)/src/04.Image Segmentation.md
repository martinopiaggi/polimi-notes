# Image Segmentation

Image segmentation involves partitioning an image into multiple segments or groups of pixels, aiming to identify pixel groups that belong together:

- Group similar-looking pixels for efficiency.
- Divide images into coherent objects.

Actually image segmentation can be divided into: 

- **Semantic Segmentation**: Assigns a label to each pixel in an image, without differentiating between different instances of the same object within a category.
- **Instance Segmentation**: Similar to semantic segmentation but also differentiates between different instances of the same object/category.

There are two types of segmentation:

- **Unsupervised Segmentation**: Group similar-looking pixels based on characteristics like color, texture, etc., without using any training data.
- **Supervised Segmentation**: Involves using labelled training data where each pixel is associated with a class label.

## Simple semantic segmentation approaches 

Simple solutions are:

- **Direct heatmap predictions**: Assigning predicted labels from a heatmap to corresponding receptive fields. Provides a coarse estimate.
- **Only convolutions**: Avoids pooling; uses only convolutional and activation layers. Results in a small receptive field and inefficiency.
- **Shift and Stich**: Assume there is a down sampling ratio $f$ between the size of input and of the output heatmap.
	- Uses a down sampling ratio $f$ between the input and output heatmap.
	- Computes heatmaps for all $f^2$ shifts of the input.
	- Interleaves the heatmaps to form a full-sized image.

### Heatmaps

**Heatmaps** are visual data displays. They use colour gradients to represent different data values.
It's possible to use heatmaps to show how convolutional filters are activated in an image. The heatmap pixels, corresponds to **receptive fields**, mark where these activations occur. These fields essentially indicate the precise spots in the input image where the associated features are detected or activated most frequently.

For image segmentation, the last layer of a CNN generates a heatmap with a unique channel per class. Each heatmap slice reflects the probability (between $0$ and $1$) of a pixel belonging to a specific class. These values are generally lower resolution than the original image.

### Up-sampling 

Up-sampling is a process that is used in convolutional neural networks (CNNs) to increase the size of the feature maps produced by the network, particularly useful in heatmap prediction. 
Up-sampling is essentially the opposite of pooling or down-sampling, increasing output resolution. 

**Image segmentation**'s primary goal necessitates the classification of each pixel in an image, often dealing with the tension between **location** (local information 'where') and **semantics** (global information 'what'). 

The key to balancing the location/semantics tension is the combination of coarse and fine layers. 

The first part of the architecture uses deep features to encode semantic information. The second half is designed to **up sample** the predictions for each image pixel. As the network gets deeper, the extracted features become more abstract and semantically rich, helping the network to identify complex patterns.
Once the semantics are encoded in the deep layers, the network includes layers for feature map **up-sampling**. Multiple techniques can be applied at this stage.

![](images/f445cf23614f05113626a2e81c5cce5a.png)

Different way to do up-sampling:

1. **Nearest Neighbour Up-sampling**: This is a simpler method of increasing the size of an image or feature map by replicating the values of the original pixels. It involves resizing the original image or feature map by inserting zero-valued pixels between the original pixels and then setting the value of each new pixel to the value of the closest original pixel. It is a simple and fast method of upsampling that can be used in a convolutional neural network (CNN).
2. **Max Unpooling**: This involves saving the positions of the maxima during max pooling and then placing the values back into their original positions during max unpooling, thereby recovering spatial position information.
3. **Transpose Convolution**: Increases the surface area of the input volume (by adding zeros) followed by convolution. This method increases the size of the output through learnable filters, which are learned during training, thereby increasing the surface area while reducing depth.
4. **Prediction Upsampling**: Employs convolutions with fractional stride filters to enlarge the image. However, the results from this method are often not optimal.
5. **Skip Connections**: In architectures like U-Net, skip connections directly connect the feature maps from downsampling (encoder) layers to the upsampling (decoder) layers. Skip connections indirectly improve the quality of the upsampling process. They enable the network to use fine-grained details along with high-level semantic information, which is especially important in tasks like super-resolution or any task that requires detailed reconstruction of an image. 


### U-Net

# TODO

U-Net is a convolutional neural network architecture that was originally developed for biomedical image segmentation. Its design is especially effective for medical imaging, where it can accurately segment complex structures while working with a limited amount of data. Here's a summary of its key features and architecture:

1. **Shape and Structure**: U-Net has a distinctive "U-shaped" architecture. It consists of two paths: a contracting (downsampling) path and an expansive (upsampling) path, which gives it the U-shaped appearance.

2. **Contracting Path**: 
    - The contracting path follows the typical architecture of a convolutional network. It consists of repeated application of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling. 
    - At each downsampling step, the number of feature channels is doubled.

3. **Expansive Path**: 
    - The expansive path consists of upsampling of the feature map followed by a 2x2 convolution (“up-convolution”) that halves the number of feature channels.
    - This is followed by a concatenation with the correspondingly cropped feature map from the contracting path, and two 3x3 convolutions, each followed by a ReLU. The cropping is necessary due to the loss of border pixels in every convolution.

4. **Skip Connections**: 
    - A key component of the U-Net is the skip connections that connect the contracting path to the expansive path. These connections provide the expansive path with context information to better localize and learn representations.

5. **Final Layer**: 
    - The final layer of the network consists of a 1x1 convolution that maps each 64-component feature vector to the desired number of classes.

6. **Output**: 
    - The output of U-Net is a segmentation map that categorizes each pixel in the input image, typically into binary classes (

object or background), although it can be extended to multi-class segmentation.

7. **

Advantages and Use Cases**:
    - U-Net's structure allows it to capture both context and localization details effectively, making it ideal for medical image segmentation where precision is crucial.
    - The network can work with a relatively small number of training images and still produce high accuracy, which is often the case in medical imaging datasets.
    - The architecture is versatile and has been adapted for various segmentation tasks beyond biomedical imaging.

8. **Training and Efficiency**:
    - U-Net is efficient in terms of GPU memory usage, which allows it to be trained even on datasets with a larger image size.
    - The overlapping tiles strategy can be used to predict the segmentation of large images in cases where memory constraints limit the image size during training.

9. **Modifications and Variations**:
    - Since its introduction, several variations of the U-Net architecture have been proposed, adapting it for different tasks and improving its efficiency and accuracy.

In summary, U-Net is a robust, efficient, and highly adaptable architecture that has set a standard in medical image segmentation and has applications in various image segmentation tasks. Its design effectively combines the context captured in the downsampling path with the localization ability in the upsampling path, enhanced by the use of skip connections.