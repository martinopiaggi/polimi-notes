
# From perceptron to Feed Forward Neural Networks

 The  neural  network  dates  back  to  the  50s.  So  when  people  started  artificial  intelligence,  they  were  already  thinking  about  the  neural  network.  goes  to  neural  networks.

 So  I'm  talking  about  hardware,  not  talking  about  software.  Nowadays,  you  think  a  neural  network  has  a  piece  of  software.  When  it  was  invented,  it  was  a  piece  of  hardware  was  a  different  way  of  building  a  machine, such  that  if  you  do  it  similar  to  a  human,  it  might  work  similar  to  a  human.  So  initially,  it  was  to  aim  at  developing  hardware  where  you  could  do  things  that  apparently  only  human  could  do.


## Perceptron


![](images/1218a0a63392a494ff2e78bd46b65cd9.png)

![](images/bfa2ea6b08791aa54a1a03291dce70f5.png)


A perceptron can be seen as a mathematical model of the neurons. We want to mimic this non-linear system where there is a sort of threshold: the signals arrive from other neurons, but only if the sum of signals exceeds the threshold the neuron activates.

The basic structure of a perceptron can be seen as:

$$
y= \begin{cases}1 & \text { if } \sum_{i=1}^{n} w_{i} x_{i}+b>0 \\ -1 & \text { otherwise }\end{cases}
$$

In this equation, $x_{1}, x_{2}, \ldots, x_{n}$ are the input features, $w_{1}, w_{2}, \ldots, w_{n}$ are the weights assigned to each input feature, $b$ is the bias term, and $y$ is the output of the perceptron. The perceptron calculates the dot product of the weights and inputs, adds the bias term, and then applies the activation function (which in this case is a step function). If the result is greater than zero, the output is 1 , and if it is less than or equal to zero, the output is -1 .

"The strength of a synapse increases according to the simultaneous activation of the relative input and the desired target"


It's a non-linear function of a linear combination. 

Sometimes the bias is just seen as another parameter $w_0$.

## Feedforward Neural Networks

Feedforward neural networks y are typically represented by composing together many different functions. The model is associated with a directed acyclic graph describing how the functions are composed together. 


These networks  have  only  information  flowing  forward,
That's  why  these  are  called  feed -forward  neurons. 

We have a chain of functions, each function feeds another function  inside the chain and they are called "layers". 

The overall length of the chain gives the depth of the model. Because the training data does not show the desired output for each of these layers, these layers are called hidden layers.

The final layer of a feedforward network is called the output layer. 

![](images/6c31d67df7cc3d06b5607c73529ffe11.png)

The structure is as it follows:

$$
z_{i}=f\left(\sum_{j=1}^{n} w_{i j} x_{j}+b_{i}\right)
$$

In a feedforward neural network, the computation of each layer is performed using this equation, where $x_{1}, x_{2}, \ldots, x_{n}$ are the input features, $w_{i j}$ is the weight of the connection between the input $\mathrm{j}$ and the output $\mathrm{i}$, bi is the bias term for the output $\mathrm{i}$, and $z_{i}$ is the output of the layer for the output $\mathrm{i}$.

The output of a node in an ANN is a linear combination of the input data and the weights of the connections between the nodes. Without an activation function, the output of the node would be a linear function of the input, which would limit the capabilities of the network to learn and model complex patterns and relationships.
By introducing an activation function, the output of the node becomes a nonlinear function of the input, which allows the network to learn and model informations like hierarchical representations. The specific type of activation function used can have a significant impact on the network's ability to learn and model different types of patterns and relationships.
- ReLu, the positive part of its argument, defined as:
$$
f(x)=x+=\operatorname{ReLU}(x)=\max (0, x)
$$

Sigmoid, maps the input values to the range between 0 and 1 , which is useful for binary classification tasks. If the output of the sigmoid function is greater than 0.5 , it is considered "activated," and the node produces an output of 1 . If the output is less than 0.5 , it is considered "deactivated," and the node produces an output of 0 .
$$
f(x)=\frac{1}{1+e^{-x}}
$$
Tanh, for the same binary mapping but between -1 and 1 .
$$
f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
$$
Softmax, used commonly in classification tasks, can map the input to a vector of values between 0 and 1 , which sum adds up to 1 . It is useful to output probability distribution.

![](images/a7a20584d06b4800812e5392d3242ee2.png)


Non-linear model characterized by the number of neurons, Activation functions, and the values of weights.
Layers are connected through weights so the output of a neuron depends only on the previous layers. 
Activation functions must be differentiable to train it

Characteristics of a non-linear model:
- It is defined by the number of neurons, activation functions, and weights.
- Neurons in different layers are connected through weights.
- The output of a neuron is determined by the previous layers.
- Activation functions used must be differentiable for effective training.

"A single hidden layer feedforward neural network with $S$ shaped activation functions can approximate any measurable function to any desired degree of accuracy on a compact set"

Universal approximation theorem (Kurt Hornik, 1991)

Which basically means that FFNN can represent any function but actually:

- finding the necessary weights may not be possible for a learning algorithm.
- In the worst case scenario, an exponential number of hidden units may be needed.
- The layer may become unreasonably large and fail to learn and generalize effectively.


Starting from a random initialization, the weights are fixed one sample at the time (online) and only if the sample is not correctly predicted. The weight of the connection between $A$ and $B$ neurons is calculated using:
$$
\left\{\begin{array}{l}
w_i^{k+1}=w_i^k+\Delta w_i^k \\
\Delta w_i^k=\eta \cdot x_i^k \cdot t^k
\end{array}\right.
$$

We are trying to minimize the cost function or loss function of the neural network. The cost function measures how well the neural network is performing on a given set of training examples. By minimizing this cost function, we aim to improve the accuracy and performance of the neural network model.
To find the minimum of a generic function, we compute the partial derivatives of the loss function in respect to the parameters and set them to zero
$$
\frac{\partial J(w)}{\partial w}=0
$$
Closed-form solutions are practically never available so we can use iterative solutions (gradient descent):

- Initialize the weights to a random value
- Decrease towards the direction of decrease
- Iterate until convergence 

$$
w^{k+1}=w^k-\left.\eta \frac{\partial J(w)}{\partial w}\right|_{w^k}
$$



Batch gradient descent
$$
\frac{\partial E(w)}{\partial w}=\frac{1}{N} \sum_n^N \frac{\partial E\left(x_n, w\right)}{\partial w}
$$

Stochastic gradient descent (SGD)

Use a single sample, unbiased, but with high variance

$$
\frac{\partial E(w)}{\partial w} \approx \frac{\partial E_{S G D}(w)}{\partial w}=\frac{\partial E\left(x_n, w\right)}{\partial w}
$$

Mini-batch gradient descent 
$$
\frac{\partial E(w)}{\partial w} \approx \frac{\partial E_{M B}(w)}{\partial w}=\frac{1}{M} \sum_{n \in \text { Minibatch }}^{M<N} \frac{\partial E\left(x_n, w\right)}{\partial w}
$$

Use a subset of samples, good trade off variance-computation

### Maximum Likelihood Estimation

MLE can be used to estimate the weights and biases of the network based on training data. 
The likelihood function is defined as the probability of the training data given the network's weights and biases. 


$$
L(w)=\prod_{i=1}^{N} p\left(y_{i} \mid x_{i}, w\right)
$$

By adjusting the weights and biases in a way that increases the probability of the training data, we can maximize the likelihood function.
To find the maximum likelihood estimate of the weight, we take the derivative of the likelihood function with respect to $w$ and set it equal to 0. Solving the resulting equation gives us the maximum likelihood estimate of the weight.
Both regression and classification can benefit from MLE in estimating model parameters and improving the accuracy of predictions.

To use MLE for regression, we need to specify a model with a set of parameters that we want to estimate. The model should be a function that describes the relationship between the input and output variables. The likelihood function is then defined as the probability of the observed output values given the model and its parameters.

In general, if we think of the distribution of the output probability as a gaussian with known variance $\sigma^{2}$ and mean $g\left(x_{n} \mid w\right)$, where this is the function of the model, the likelihood for a regression model can be defined as follows:

$$
L(w)=\prod_{i=1}^{N} p\left(t_{i} \mid g\left(x_{i} \mid w\right), \sigma^{2}\right)
$$

where $w$ is the set of model parameters and $p\left(t_{i} \mid g\left(x_{i} \mid w\right), \sigma^{2}\right)$ is the probability of the true output given the input and the parameters. This formula can be maximized using the sum of squared errors:

$$
\operatorname{argmin}_{w}\left(\sum_{i=1}^{N}\left(t_{i}-g\left(x_{i} \mid w\right)\right)^{2}\right)
$$

For classification we use Bernoulli distributions binary cross-entropy as a useful error function:

$$
\operatorname{argmin}_{x}\left(-\sum_{n=1}^{N} t_{n} \log \left(g\left(x_{n} \mid w\right)\right)+\left(i-t_{n}\right) \log \left(1-g\left(x_{n} \mid w\right)\right)\right)
$$


## Error functions

An error function, or "loss function," is used to measure how well a feedforward neural network (FFNN) can predict the desired output given input data. It guides the optimization process during training.

To use an error function in an FFNN:

- Define the error function based on the task, such as mean squared error (MSE) for regression or binary cross-entropy loss for binary classification. The binary cross-entropy loss is calculated as the negative log likelihood of the predicted probabilities. 
- Calculate the error by applying the error function to the predicted and true outputs.
- Backpropagate the error through the network using an optimization algorithm, like stochastic gradient descent (SGD), to update the weights and biases.
- Evaluate the error to assess performance on the training and validation/test data.

Common error functions used in FFNNs include:

- Mean squared error (MSE) for regression tasks.
- Binary cross-entropy loss for binary classification tasks.
- Categorical cross-entropy loss for multi-class classification tasks.
- Hinge loss for binary classification tasks, commonly used in support vector machines (SVMs).

Other error functions can also be used depending on the task requirements.


... 


Hebbian learning 

From a geometrical POV 

The signed distance of any point $\mathrm{x}$ from $L \in \mathfrak{R}^2$ is defined by
$$
w^{* T}\left(\mathrm{x}-\mathrm{x}_0\right)=\frac{1}{\|w\|}\left(w^T \mathrm{x}+w_0\right)
$$

It can be shown, the error function the Hebbian rule is minimizing is the distance of misclassified points from the decision boundary.

Remember that 

Any two points $\mathrm{x}_1$ and $\mathrm{x}_2$ on $L \in \mathfrak{R}^2$ have
$$
w^T\left(\mathrm{x}_1-\mathrm{x}_2\right)=0
$$
The versor normal to $L \in \mathfrak{R}^2$ is then
$$
w^*=w /\|w\|
$$


where $L$ is the hyperplane which in $R^2$ is just a line. 

Just saying ... An affine set is a subset of a vector space that contains all the affine combinations of its points. In other words, it is a set where any point can be expressed as a linear combination of two or more points in the set, with coefficients summing up to 1. An affine set can be thought of as a flat plane or hyperplane within the vector space.



Let's code the perceptron output as $+1 /-1$
- If an output which should be +1 is misclassified then $\mathrm{w}^{\mathrm{T}} \mathrm{x}+\mathrm{w}_0<0$
- For an output with -1 we have the opposite
The goal becomes minimizing
$$
D\left(w, w_0\right)=-\sum_{i \in \mathrm{M}} t_i\left(\mathrm{w}^{\mathrm{T}} \mathrm{x}_{\mathrm{i}}+\mathrm{w}_0\right)
$$
This is non negative and proportional to the distance of the misclassified points from $\mathrm{w}^{\mathrm{T}} \mathrm{x}+\mathrm{w}_0=0$
Let's minimize by stochastic gradient descend the error function

$$
D\left(w, w_0\right)=-\sum_{i \in \mathrm{M}} t_i\left(\mathrm{w}^{\mathrm{T}} \mathrm{x}_{\mathrm{i}}+\mathrm{w}_0\right)
$$



Hebbian learning implements Stocastic Gradient Descent