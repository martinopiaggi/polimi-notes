
# From perceptron to Feed Forward Neural Networks

The concept of neural networks has been around since the 1950s. Initially, it involved building hardware that could mimic human-like behaviour and perform tasks that only humans were thought to be able to do. 
## Perceptron

![](images/1218a0a63392a494ff2e78bd46b65cd9.png)

![](images/bfa2ea6b08791aa54a1a03291dce70f5.png)


A perceptron can be seen as a mathematical model of the neurons. We want to mimic this non-linear system where there is a sort of **threshold**: the signals arrive from other neurons, but only if the sum of signals exceeds the threshold the neuron activates.

The basic structure of a perceptron can be seen as:

$$
y= \begin{cases}1 & \text { if } \sum_{i=1}^{n} w_{i} x_{i}+b>0 \\ -1 & \text { otherwise }\end{cases}
$$

In this equation, $x_{1}, x_{2}, \ldots, x_{n}$ are the input features, $w_{1}, w_{2}, \ldots, w_{n}$ are the weights assigned to each input feature, $b$ is the bias term, and $y$ is the output of the perceptron. The perceptron calculates the dot product of the weights and inputs, adds the bias term, and then applies the activation function (which in this case is a step function). If the result is greater than zero, the output is 1 , and if it is less than or equal to zero, the output is -1 .

> "The strength of a synapse increases according to the simultaneous activation of the relative input and the desired target" *(Donald Hebb, The Organization of Behaviour, 1949)*

It's a **non-linear** function of a linear combination: the inputs are combined linearly (sum of weighted inputs plus a bias), and then this result is transformed by a **non-linear** function (the activation function).

Why this non-linearity is so important? 

- Linear models can only represent linear relationships. Non-linear functions in neural networks can approximate a wider range of functions, including intricate and complex relationships in data. 
- Non-linear activation functions also allow for the stacking of layers in deep neural networks which would not be possible with linear functions which would collapse into a single linear layer. 
- Many real-world phenomena are non-linear, so non-linear representations are necessary to accurately reflect them.

Sometimes the bias is just seen as another parameter $w_0$.

## Feedforward Neural Networks

Feedforward neural networks are typically represented by composing together many different functions. 
The model is associated with a **directed acyclic graph** describing how the functions are composed together. 

These networks have only information flowing forward in a **chain of functions** (that's why are called **feed-forward** neurons) called **layers**.

The depth of the model is determined by the number of layers in the chain. 


![](images/6c31d67df7cc3d06b5607c73529ffe11.png)

The structure is as it follows:

$$
z_{i}=f\left(\sum_{j=1}^{n} w_{i j} x_{j}+b_{i}\right)
$$

In a feedforward neural network, the computation of each layer is performed using this equation, where $x_{1}, x_{2}, \ldots, x_{n}$ are the input features, $w_{i j}$ is the weight of the connection between the input $j$ and the output $i$, $b_i$ is the bias term for the output $\mathrm{i}$, and $z_{i}$ is the output of the layer for the output $i$.

The specific type of activation function used can have a significant impact on the network's ability to learn and model different types of patterns and relationships.

- ReLu, the positive part of its argument, defined as:
$$
f(x)=x+=\operatorname{ReLU}(x)=\max (0, x)
$$

Sigmoid, maps the input values to the range between 0 and 1 , which is useful for binary classification tasks. If the output of the sigmoid function is greater than 0.5 , it is considered "activated," and the node produces an output of 1 . If the output is less than 0.5 , it is considered "deactivated," and the node produces an output of 0 .
$$
f(x)=\frac{1}{1+e^{-x}}
$$
Tanh, for the same binary mapping but between -1 and 1 .
$$
f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
$$
Softmax, used commonly in classification tasks, can map the input to a vector of values between 0 and 1 , which sum adds up to 1 . It is useful to output probability distribution.

![](images/a7a20584d06b4800812e5392d3242ee2.png)


Non-linear model characterized by the number of neurons, Activation functions, and the values of weights.
Layers are connected through weights so the output of a neuron depends only on the previous layers. 
Activation functions must be differentiable to train it

Characteristics of a non-linear model:

- It is defined by the number of neurons, activation functions, and weights.
- Neurons in different layers are connected through weights.
- The output of a neuron is determined by the previous layers.
- Activation functions used must be differentiable for effective training.

### Universal approximation theorem (Kurt Hornik, 1991)

> "A single hidden layer feedforward neural network with $S$ shaped activation functions can approximate any measurable function to any desired degree of accuracy on a compact set" (Kurt Hornik, 1991)

Which basically means that FFNN can represent any function but actually:

- finding the necessary weights may not be possible for a learning algorithm.
- In the worst case scenario, an exponential number of hidden units may be needed.
- The layer may become unreasonably large and fail to learn and generalize effectively.

Starting from a random initialization, the weights are fixed one sample at the time (online) and only if the sample is not correctly predicted. The weight of the connection between $A$ and $B$ neurons is calculated using:

$$
\left\{\begin{array}{l}
w_i^{k+1}=w_i^k+\Delta w_i^k \\
\Delta w_i^k=\eta \cdot x_i^k \cdot t^k
\end{array}\right.
$$

We are trying to minimize the cost function or loss function of the neural network. The cost function measures how well the neural network is performing on a given set of training examples. By minimizing this cost function, we aim to improve the accuracy and performance of the neural network model.
To find the minimum of a generic function, we compute the partial derivatives of the loss function in respect to the parameters and set them to zero
$$
\frac{\partial J(w)}{\partial w}=0
$$

### Gradient descent

Closed-form solutions are practically never available so we can use iterative solutions (**gradient descent**):

- Initialize the weights to a random value
- Decrease towards the direction of decrease
- Iterate until convergence 

$$
w^{k+1}=w^k-\left.\eta \frac{\partial J(w)}{\partial w}\right|_{w^k}
$$

#### Batch gradient descent

$$
\frac{\partial E(w)}{\partial w}=\frac{1}{N} \sum_n^N \frac{\partial E\left(x_n, w\right)}{\partial w}
$$

#### Stochastic gradient descent (SGD)

Use a single sample, unbiased, but with high variance

$$
\frac{\partial E(w)}{\partial w} \approx \frac{\partial E_{S G D}(w)}{\partial w}=\frac{\partial E\left(x_n, w\right)}{\partial w}
$$

####  Mini-batch gradient descent 
$$
\frac{\partial E(w)}{\partial w} \approx \frac{\partial E_{M B}(w)}{\partial w}=\frac{1}{M} \sum_{n \in \text { Minibatch }}^{M<N} \frac{\partial E\left(x_n, w\right)}{\partial w}
$$

Use a subset of samples, good trade off variance-computation

#### Gradient descend optimizers 






### Hebbian learning 

From a geometrical POV 

The signed distance of any point $\mathrm{x}$ from $L \in \mathfrak{R}^2$ is defined by
$$
w^{* T}\left(\mathrm{x}-\mathrm{x}_0\right)=\frac{1}{\|w\|}\left(w^T \mathrm{x}+w_0\right)
$$

It can be shown, the error function the Hebbian rule is minimizing is the distance of misclassified points from the decision boundary.

Remember that 

Any two points $\mathrm{x}_1$ and $\mathrm{x}_2$ on $L \in \mathfrak{R}^2$ have
$$
w^T\left(\mathrm{x}_1-\mathrm{x}_2\right)=0
$$
The versor normal to $L \in \mathfrak{R}^2$ is then
$$
w^*=w /\|w\|
$$


where $L$ is the hyperplane which in $R^2$ is just a line. 

Just saying ... An affine set is a subset of a vector space that contains all the affine combinations of its points. In other words, it is a set where any point can be expressed as a linear combination of two or more points in the set, with coefficients summing up to 1. An affine set can be thought of as a flat plane or hyperplane within the vector space.



Let's code the perceptron output as $+1 /-1$
- If an output which should be +1 is misclassified then $\mathrm{w}^{\mathrm{T}} \mathrm{x}+\mathrm{w}_0<0$
- For an output with -1 we have the opposite
The goal becomes minimizing
$$
D\left(w, w_0\right)=-\sum_{i \in \mathrm{M}} t_i\left(\mathrm{w}^{\mathrm{T}} \mathrm{x}_{\mathrm{i}}+\mathrm{w}_0\right)
$$
This is non negative and proportional to the distance of the misclassified points from $\mathrm{w}^{\mathrm{T}} \mathrm{x}+\mathrm{w}_0=0$
Let's minimize by stochastic gradient descend the error function

$$
D\left(w, w_0\right)=-\sum_{i \in \mathrm{M}} t_i\left(\mathrm{w}^{\mathrm{T}} \mathrm{x}_{\mathrm{i}}+\mathrm{w}_0\right)
$$


Hebbian learning implements Stochastic Gradient Descent


### Activation functions 


## Error functions

An error function, or "loss function," is used to measure how well a feedforward neural network (FFNN) can predict the desired output given input data. It guides the optimization process during training.

To use an error function in an FFNN:

- Define the error function based on the task, such as mean squared error (MSE) for regression or binary cross-entropy loss for binary classification. The binary cross-entropy loss is calculated as the negative log likelihood of the predicted probabilities. 
- Calculate the error by applying the error function to the predicted and true outputs.
- Backpropagate the error through the network using an optimization algorithm, like stochastic gradient descent (SGD), to update the weights and biases.
- Evaluate the error to assess performance on the training and validation/test data.

Common error functions used in FFNNs include:

- Mean squared error (MSE) for regression tasks.
- Binary cross-entropy loss for binary classification tasks.
- Categorical cross-entropy loss for multi-class classification tasks.
- Hinge loss for binary classification tasks, commonly used in support vector machines (SVMs).

Other error functions can also be used depending on the task requirements.
