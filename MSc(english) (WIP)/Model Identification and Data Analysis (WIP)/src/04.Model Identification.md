
# Model identification

The focus of the course is on mathematical models describing phenomena or systems.

![](images/Pasted%20image%2020240225165158.png)


Model identification process answers to the question "How can I obtain a model?"

We would like to make a model relying on data as the source like in [Machine Learning](../../Machine%20Learning/Machine%20Learning.md) .


An **identification problem** consists of four elements: 

- $S$ a system generating data
- $M$ a model used to explain the system:
	- **White-box**:
		- Pros:
			- Physical meaning of variables
			- The model can be generalized
		- Cons:
			- Everything must be known exactly a-priori
			- Expensive and time-consuming
			- Non feasible with complex systems
	- **Black-box**: 
		- Pros:
			- Implementable even without deep process knowledge
			- Fast and cheap
		- Cons:
			- Non physically interpretable
			- Non general: if the system changes, the experiment must be repeated


an identification algorithm to find the best model

- $I$ an identification experiment to obtain data. The system, model, identification algorithm, and identification experiment make up an identification problem. Data provided can limit the model's ability to extract more information than what's available. The model can only extract information that exists within it. For instance, steady-state data can provide information about a system's gain but cannot provide information related to its time constant. The linear model is an example of a commonly used model, but its assumptions may not always hold, requiring different optimization algorithms.



## Parametric system identification 


$$M=y(t)=\frac{B(z,\theta)}{A(z,\theta)}\mu(t-d)+\frac{C(z,\theta)}{A(z,\theta)}e(t)$$

where $\theta$ are the parameters $\in \mathbb{H}$ (the parameters domain). 

We must decide $\theta$ but also $\lambda^2$ , $d$,$m$,$p$,$n$ . 

PEM identification (prediction error minimization)

A good model should return a low emprical variance of the prediction error:

$$J_N(\vartheta)=\frac{1}{N}\sum_{i=1}^{N}\left(\mathrm{y}(i)-\hat{y}(i\mid i-1,\vartheta)\right)^2=\frac{1}{N}\sum_{i=1}^{\text {\# samples}}\varepsilon(i,\vartheta)^2$$


we would like to minimize it. 



### Identification of ar/arx models 

$$y(t)=\frac{B(z)}{A(z)}u(t-d)+\frac1{A(z)}e(t)$$

$$A(z)=1-z^{-1}-^{-2}-\cdots-2mz$$$$B(z)=b_{o}+b_{1}z^{-1}+b_{2}z^{-2}+\cdots-b_{p-1}z^{-p+1}$$ 

and since AR has no MA port:

$$C(z)=1\quad\color{red}$$

Explicit minimization is possible 


$$\hat{\vartheta}_N=\left(\sum_{t=1}^N\varphi(t)\varphi^T\left(t\right)\right)^{-1}\sum_{t=1}^Ny(t)\varphi(t)$$



We have a set of data $y(1), y(2), \dots (u(1), u(2), \dots)$ and we want to find the best model that approximate these data. 

In this discussion, we focus on parametric identification of dynamic systems. The process involves five main steps: 

1) designing experiments
2) selecting models
3) defining quality measures
4) optimizing models
5) checking model validity. 

The first step is transforming given data into specific parameter values to learn a model. Parametric identification simplifies mathematics but requires identifying a model with specific parameters, making the process more complex.

An identification problem is essentially a parametric optimization problem. We recast the learning problem as an optimization task with a quadratic cost function, seeking the minimum stationary point to find the optimal parameters.

A positive definite matrix is a quadratic matrix where the associated quadratic form, represented as $x^T M x$, is positive for any non-zero vector x. The speaker explains that a positive matrix, where all elements are positive, is not the same as a positive definite matrix. 


$$J(\vartheta)=\frac1N\sum_{t=1}^N\left(y(t)-\varphi(t)^T\vartheta\right)^2$$


The hessian is then always positive semi-definite and two case happens: 

1) hessian is singular 
2) hessian is invertible 

In the generative paraboloid case, multiple global minimums are found but it is an error since it's known that only one system originated the data. 

Multiple global are not feasible solutions and this can happen because:

- **over**: the chosen models are too complex for the system 
- **under**: data isn't representative enough 


Identifiability We say that the system is identifiable when the above equation admits only one solution. This happens when the matrix


In ideal situations, where data is thoroughly explored and the right model class is selected, the optimization problem will be well-posed, ensuring a minimum solution. This concept applies to both AR and ARMAX models.

For ARMAX models, the identification process uses the maximum likelihood approach. 


We want to minimize

$$
J(\vartheta)=\frac1N\sum_{t=1}^N\varepsilon_\vartheta(t)^2
$$

but this time the relation with the parameters $\vartheta$ is not linear anymore. Therefore, we need to use an iterative method.

The prediction error epsilon\_t at time t given data up to t-1 is dependent on the coefficients of the z polynomial non-linearly. This non-linear dependence was the reason for the use of the least squares formula in the past due to its linear dependence on the coefficients a and b. However, since theta contains the coefficient of c, the optimization problem becomes non-linear, requiring numerical approaches for solution. 

An iterative numerical method such as gradient descent can be used with an initial estimate theta\_1 and an update rule that computes the next guess for theta based on the previous iteration's y and an update to the parameters. 

The speaker discusses the issue of local optima in optimization and mentions the Newton=n method as a potential solution. In the context of R Max models, the method involves taking the quadratic expansion of the cost function and finding the minimum of the resulting paraboloid to update the parameter.


![](images/Pasted%20image%2020240315154109.png)

The speaker is discussing the second-order Taylor expansion of a cost function J with respect to a variable theta. They explain that to find vi, the second-order term, we need to compute the gradient and Hessian of the cost function and plug them into the expression. The condition for the minimum of vi occurs when theta i plus one is the value of theta for a stationary point. The update rule for the next guess of theta is derived using Newton's approach, which involves taking the inverse of the Hessian and pre-multiplying it with the difference between theta i plus one and theta i. The speaker emphasizes that this calculation is only used as a tool to obtain the final update, and they will actually work with the Hessian and gradient of the original cost function to find a variation of the current guess of theta from the data.

We can compute the cost function directly from data if we have the correct initial condition, resulting in the global solution. Each iteration requires retrieving the gradient and Hessian or its inverse from the data. 



The speaker discusses the second term in the Newton's method, which is often neglected due to it potentially being negative and small when close to the optimal solution. The matrix involved in the method, Hessian, is positive semi-definite, ensuring the method moves towards the minimum. The second term's negligibility arises from being small near the solution and the Hessian's positive semi-definiteness, making the Newton's method safer. 

The formula for the Newton's method is rewritten using the gradient and the action of the cost function. The matrix dimensions are confirmed as consistent, resulting in a column vector representing the variation of theta with respect to theta i.




 The derivative of the error function epsilon with respect to the parameter theta is required to compute the gradient for optimization. While we have an expression for epsilon, the derivative is unknown. We need to find the derivative of epsilon with respect to each coefficient in theta, including a, m, b, and c. We write epsilon as an explicit function of these coefficients and compute the derivatives in classes: first for the parameters characterizing a, then for b, and finally for c. The derivative of epsilon with respect to a one is z - 1 multiplied by (a - 1) over c times y. We define a new signal, alpha t, as -1/c * y, and the derivative of epsilon with respect to a one is equivalent to alpha t - 1.


The fact that Hessian is $\ge 0$ is good in terms of "safety" of the method

![](images/Pasted%20image%2020240315161420.png)

The second term is likely to be "small" close to the minimum (at the end of the iterations)

and if we neglect the second order derivative term we also have



$$\frac{\partial^2J(\vartheta)}{\partial\vartheta^2}=\frac1N\sum_{t=1}^N\varphi_\vartheta(t)\varphi_\vartheta(t)^T$$

so the new iteration formula is

$$\vartheta^{(r+1)}=\vartheta^{(r)}-\left[\frac1N\sum_{t=1}^N\varphi_\vartheta(t)\varphi_\vartheta(t)^T\right]^{-1}\left[\frac1N\sum_{t=1}^N\varphi_\vartheta(t)\varepsilon_\vartheta(t)\right]$$

![](images/Pasted%20image%2020240315161623.png)



![](images/Pasted%20image%2020240315161942.png)





This method is one way to solve a numerical optimization algorithm, but there are other methods as well.

$$\theta^{(i+i)}=\theta^{(i)}-[\text{hessian}]^{-1}-\text{gradient}$$


while the gradient descent:

$$\theta^{(i+1)}=\theta^{(i)}-\eta \cdot \text{gradient},$$

Same philosophy since both moves in the directions where the right direction.

The newton's rule depending on the region you are "moves" smarter and uses less iterations ( so it's more computational efficient)

The quasi newton is computationally lighter than Newwton's (we neglect a part) but at the same time is more accurate than the gradient descent method

$$Q^{(i+1)}=\theta^{(i)}-[\text{approximate Hession}]\cdot \text{gradient}$$


 Quasi-Newton methods, such as BFGS, use an approximate Hessian to strike a balance between accuracy and computational efficiency. These methods are safer because they avoid the issue of encountering negative definite conditions and require fewer computations than Newton's method. However, they may introduce some inaccuracy in the computation of the Hessian at the beginning.

In optimization, gradient descent is a common method used to find the minimum of a function. The gradient tells you the direction and the magnitude of the next step. Variants of gradient descent exist, such as **time-varying** ones, but in the context of system identification with a limited number of parameters, the quasi-Newton rule is typically used. 


In NN gradient descent variants are more effective (since the are a lot of parameters) .

In this framework (system identification) we use quasi-newton's rule.