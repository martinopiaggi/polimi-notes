# Model prediction 

We want to find the predictor $\hat y (t)$ of process $y(t)$ from the past values of $y$. 

![](images/Pasted%20image%2020240320184427.png)

Steps:

0) analysis of the system
1) evaluation of the canonical representation of the system 
2) computation of the predictor 
3) evaluate the prediction error

The variance of the prediction is the variance of the process if it is optimal.

## ARMA

Note that the variance of the error increases with $r$, meaning that more distant prediction result to be less precise. Practically $\hat v(t + r|t) = \hat W(z) \eta(t)$, where $W(z)$ is the result of the $r$-step long division of the numerator and denominator of $W(z)$ in canonical form.

$$W(z)=\frac{C(z)}{A(z)}=\text{long division}=E(z)+\frac{z^{-u}F(z)}{A(z)}$$
where $E(z)$ is the result of the long division, while $F(z)$ is the rest. 
So:

$$y(t+k)=\frac{C(z)}{A(z)}e(t+k)=\left[E(z)+z^{-k}\frac{F(z)}{A(z)}\right]e(t+k)$$

In practice what happens is that the $E(z)e(t+k)$ part will be always be discarded and treated as the prediction error, while this $z^{-k}\frac{F(z)}{A(z)}e(t+k)$ can be use. 

Actually to be used in a clever way we will use this $e(t)=\frac{A(z)}{C{z}}y(t)$ to obtain the predictor from data: 

$$\hat{y}(t+n|t)=\frac{F(z)}{A(z)}e(t)=\frac{F(z)}{A(z)}\cdot\frac{A(z)}{C(z)}\cdot y(t)=\frac{F(z)}{C(z)}y(t)$$

Remember:

- $\hat y(t+k,s)$ is a stochastic process, **stationary** (because the denominator $C(z)$ still has roots inside the unit circle).
- The quality of the prediction get worse with increasing $k$.
- Asymptotically the **variance of the prediction erro**r tends to the variance of the predicted process $y(t)$.

$$var[\epsilon(t|t-k)]=\mathbb E [y(t) -\hat y(t|t-k) ]=var[y(t)]$$
- $var[e(t)]\leq var[e(t+k(t))]<var[y(t)]$ 

### 1-step predictor

If you use the previously presented formula for a 1 step ARMA predictor with null mean you will always obtain $E(z)=0$. This aspect permits to make some semplification in the final formula and just use these "shortcuts":

$$\hat{y}(t|t-1)=\frac{C(z)-A(z)}{A(z)}e(t)$$
from data: 

$$\hat{y}(t|t-1)=\frac{C(z)-A(z)}{C(z)}y(t)$$
And since:

$$\epsilon(t|t-1)=y(t)-\hat{y}(t|t-s)=y(t)-\frac{C_m-A_m}{C_m}y(t)=\left(\frac{C_m-C_m+A_m}{C_m}\right)y(t)$$
the prediction error will always be:
$$\epsilon(t|t-1)=\frac{A_m(z)}{C_m(z)}\cdot y(t)$$

### ARMA with not null mean

Remember that for [processes with non-null term](projects/polimi-notes/MSc(english)%20(WIP)/Model%20Identification%20and%20Data%20Analysis%20(WIP)/src/02.MA,%20AR%20and%20ARMA%20processes.md#Processes%20with%20non-null%20term) we have some troubles? Also when computing predictors with not null mean we have to make some sbatti: 

$$\begin{aligned}y(t+k)&=\hat{y}(t+k)+my\\\hat{y}(t+k|t)&=\hat{y}(t+k|t)+my\end{aligned}$$
To make the predictor we have to just consider the unbiased process, so first of all compute the mean with gain theorem:
   $$ E[y(t)] = W(1) \cdot \mu = my $$

Then define **de-biased** processes:
   $$\begin{align*}
   \tilde{y}(t) &= y(t) - my \\
   \tilde{e}(t) &= e(t) - \mu
   \end{align*}$$

Redefine the process using unbiased elements:
   $$ \tilde{y}(t+k|t) = \frac{C(z)}{A(z)} \cdot \tilde{e}(t)$$
And apply the generic formulas for the predictor.
At the end we can make the prediction adjustment for non-zero-mean:
   $$ \hat{y}(t+k|t) = \tilde{y}(t+k|t) + my $$
$$\begin{aligned}\hat{y}(t+k|t)&=\frac{F(z)}{C(z)}\tilde{y}(t)+my=\frac{F(z)}{C(z)}(y(t)-my)+my\\&=\frac{F(z)}{C(z)}y(t)-\frac{F(z)}{C(1)}my+my\end{aligned}$$
   
and the final formula is: 
   $$ \hat{y}(t+k|t) = \frac{F(z)}{C(z)} \cdot y(t) + \left(1 - \frac{F(1)}{C(1)}\right) \cdot my $$

## ARX and ARMAX

We want to predict the generic ARMAX process: 

$$y(t)=\frac{C(z)}{A(z)}e(t)+\frac{B(z)}{A(z)}u(t-d)$$
where $d$ is the pure delay.
Assuming already canonical $\frac{C(z)}{A(z)}$ and $u(t)$ known process (so completely **deterministic**) we only need predictor for stochastic part. Said this we compute the predictor in a similar way as before: 

$$z(t)=y(t)-\frac{B(z)}{A(z)}u(t-d)=\frac{C(z)}{A(z)}e(t)$$
and so defining the predictor as: 

$$\hat{z}(t+n|t)=\frac{F(z)}{C(z)}z(t)$$
then considering that $y(t)=\frac{B(z)}{A(z)}u(t-d)+z(t)$ :

$$\hat{y}(t+n|t)=\frac{B(z)}{A(z)}u(t+k-d)+\hat{z}(t+k|t)$$

then replace the predictor of $\hat z$:

$$
\begin{aligned}
\hat{y}(t+k|t) &= \frac{B(z)}{A(z)}u(t+k-d) + \frac{F(z)}{C(z)}z(t) \\
&= \frac{B(z)}{A(z)}u(t+k-d) + \frac{F(z)}{C(z)}\left(y(t) - \frac{B(z)}{A(z)}u(t-d)\right) \\
&= \frac{B(z)}{C(z)}\left[\frac{C(z)}{A(z)} - \frac{F(z)}{A(z)}z^{-k}\right]u(t+k-d) + \frac{F(z)}{C(z)} \cdot y(t)
\end{aligned}
$$

Lastly, to understand last semplification, keep in consideration the diophantine equation:

$$\frac{C(z)}{A(z)} = E(z) + \frac{F(z)}{A(z)}z^{-k}$$

using it, we can replace $\left[\frac{C(z)}{A(z)} - \frac{F(z)}{A(z)}z^{-k}\right]$ with $E(z)$ to obtain a "simple" elegant equation with depends only on past data of $u(t)$ and $y(t)$ :

$$\hat{y}(t+k|t)=\frac{B(z)E(z)}{C(z)}\cdot u(t+k-d)+\frac{F(z)}{C(z)}y(t)$$


