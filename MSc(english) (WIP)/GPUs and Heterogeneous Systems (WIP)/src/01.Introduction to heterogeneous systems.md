
# Introduction to heterogeneous systems

An **heterogeneous System** comprises multiple computing units, each with distinct characteristics. Heterogeneous systems are necessary since the need to run applications in various fields with differing performance requirements (Email, browser, videogames , cad ... etc). 

## Why heterogeneous systems

What are the motivations, challenges, and real-world examples of heterogeneous systems?

**Motivations**:

1. The need for high performance and energy efficiency in modern devices, which are **power-constrained**.
2. Many compute-intensive applications can be partitioned into parts with different characteristics, **each of which can be efficiently accelerated by a different type of computing unit**.

**Challenges**:

1. **Integration** of many different units and **communication** between them.
2. **Programmability**, as each type of unit has different programming languages and paradigms.
3. **Resource management**, including distributing a multi-programmed dynamic workload, configuring software/hardware knobs, and achieving required performance at a power-efficient level.

Real-world examples are infinite: mobile phones, laptops, desktop computers, embedded and edge devices, and supercomputers. 

## Evolution of Computing System Architectures
    
- **Single-Core Era**: This era was characterized by increasing voltage/frequency scaling until the power wall was reached in 2004.
- **Multi-Core Era**: This era saw the integration of multiple cores in the same chip. However, performance limits were encountered due to power consumption and scalability issues.
- **Heterogeneous Systems Era**: marked by the integration of heterogeneous units in the same chip, allowing for parallelization of various applications. Different parts of the applications may benefit from specialized computing units.

## Parallelism 

**Task Parallelism**: This involves the execution of many independent tasks/functions in parallel.
**Data Parallelism**: This involves operations on data composed of many items that can be processed simultaneously.

## Flynn's Taxonomy
    
This taxonomy classifies system architectures based on instructions and data into categories like SISD, SIMD, MISD, MIMD, SPMD, and MPMD.

7. **Architectural Solutions for Parallel Computing**:
    - These solutions exploit Instruction-Level Parallelism (ILP), Data-Level Parallelism (DLP), and Thread-Level Parallelism (TLP) and include architectures like pipelined, superscalar, VLIW, SIMD, Interleaved Multi-Threading, Simultaneous Multi-Threading, and Multicore.

1. **GPU Parallelism**:
    - GPUs exploit Data-Level Parallelism (DLP), where groups of ALUs execute the same operation on different data items simultaneously.
